{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import predict as pt\n",
    "import train\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import glob, os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import orderedDict\n",
    "\n",
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.RandomCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = torch.utils.data.DataLoader(image_datasets, batch_size=32, shuffle=True)\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=data_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "valid_data = datasets.ImageFolder(data_dir + '/valid', transform=data_transforms)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=32) \n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32) \n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "    \n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for linear in self.hidden_layers:\n",
    "            x = F.relu(linear(x))\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "vgg16 = models.vgg16()\n",
    "model = models.vgg16(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(1024, 500)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(500, 2)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "                          ]))\n",
    "\n",
    "model.classifier = classifier\n",
    "\n",
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images.resize_(images.shape[0], 784)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy\n",
    "epochs = 2\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 40\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        steps += 1\n",
    "        \n",
    "        images.resize_(images.size()[0], 784)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "            \n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n",
    "            \n",
    "save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': args.arch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "model.class_to_idx = image_datasets['train'].class_to_idx\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth')\n",
    "\n",
    "\n",
    "checkpoint = torch.load('flowers')\n",
    "model = getattr(torchvision.models, checkpoint['arch'])\n",
    "model.classifier = checkpoint['classifier']\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.optimizer = checkpoint('optimizer')\n",
    "return model\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    \n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    if img.size[0]>=img.size[1]: \n",
    "        img.thumbnail((10000,256)) \n",
    "    else: \n",
    "        img.thumbnail((256,10000))    half_the_width = image.size[0] / 2\n",
    "    half_the_height = image.size[1] / 2\n",
    "    image = image.crop((half_the_width - 112,\n",
    "                       half_the_height - 112,\n",
    "                       half_the_width + 112,\n",
    "                       half_the_height + 112))\n",
    "\n",
    "    np_image = np.array(image)\n",
    "    np_image = np.array(np_image)/255\n",
    "\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std_dev = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    image = (np_image - mean) / std_dev\n",
    "    image = image.transpose((2, 0, 1))\n",
    "\n",
    "    return torch.from_numpy(image)\n",
    "\n",
    "\n",
    "\n",
    "def imshow(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    ax.imshow(image)  \n",
    "    return ax\n",
    "\n",
    "\n",
    "def predict('flowers', model, topk=5):\n",
    "    probs, classes = predict('flowers', model)\n",
    "    probs = class_to_idx\n",
    "    k = torch.sort(input, dim=None, descending=False, out=None) -> (Tensor, LongTensor)\n",
    "    torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor)\n",
    "    return probs\n",
    "    return classes\n",
    "\n",
    "\n",
    "k.imshow(topk)\n",
    "print(torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
